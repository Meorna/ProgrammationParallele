Instructions pour compiler et exécuter le code et utiliser le makefile : 
    Compiler : make 
    Exécuter : mpirun -np 3 ./exe 
    Nettoyer : make clean 
    Créer doc : make doc 
    Créer archive : make give 

Fonctionnement du code : 
    main.c: 
        int main(int argc, char const *argv[]) : Pour commencer on initialise l'environnement MPI, on récupère le nombre de processus et le rang du processus en cours, 
        on vérifie que le reste de la division euclidienne du nombre de ligne de la matrice A est bien divisible par le nombre de processus lancé par l'utilisateur, 
        si oui on divise le nombre de ligne par le nombre de processus pour obtenir le nombre d'éléments pour chaque sous matrice, 
        sinon on affiche un message d'erreur et on termine l'exécution de l'environnement. 
        Ensuite, si le processus en cours a pour valeur 0 on initialise les matrices A et B avec des entiers. 
        Pour continuer, le processus 0 partage la matrice B aux autres processus puis divise la matrice A en sous matrice pour partager chaque sous matrice à un processus. 
        Chaque sous-matrice calcule sa partie du produit matricielle puis les calculs sont rassemblés. Si on se trouve dans le processus 0 on affiche la matrice C qui contient le résultat. 
        Pour finir, on désactive l'environnement MPI.
            MPI_Init(&argc,&argv) : Initialiser l'environnement MPI. 
            MPI_Comm_size(MPI_COMM_WORLD, &nombreProcessus) : Retourner le nombre de processus. 
            MPI_Comm_rank(MPI_COMM_WORLD, &rang) : Retourner le rang du processus en cours. 
            printf(texte) : Ecrire un message dans la console. 
            fprintf(stderr, nombreColonneA = %d doit être divisible par nombreProcessus = %dn, nombreColonneA, nombreProcessus) : Ecrire dans un fichier erreur et afficher dans la console. 
            MPI_Abort(MPI_COMM_WORLD, 1) : Terminer l'environnement MPI avec un code retour d'erreur. 
            MPI_Bcast(B, nombreColonneA * nombreColonneB, MPI_INT, 0, MPI_COMM_WORLD) : Partager à tous les processus la matrice d'entier B à partir du processus 0. 
            MPI_Scatter(A, nombreColonneA * nombreElement, MPI_INT, A[rang * nombreElement], nombreColonneA * nombreElement, MPI_INT, 0, MPI_COMM_WORLD) : Diviser la matrice d'entier A par nombre de nombreElement lignes qui seront distribués entre tous les processus. 
            MPI_Gather(C[rang * nombreElement], nombreColonneB * nombreElement, MPI_INT, C, nombreColonneB * nombreElement, MPI_INT, 0, MPI_COMM_WORLD) : Rassembler les valeurs détarminées par tous les processus. 
            MPI_Finalize() : Finaliser l'environnement MPI. 

Décision de design : 
    Pour cet exercice, j'ai décidé de ne pas utilisé la base de code proposé par le professeur mais plutôt de reprendre la base de l'exercice deux que j'ai fait. 
    Au lieu d'utiliser la fonction MPI_Reduce_scatter j'ai d utiliser la fonction MPI_Gather pour faire marcher mon code.

Résultat obtenu : 
    Nombre Processus : 3, Rang : 2 
    Nombre Processus : 3, Rang : 1 
    Nombre Processus : 3, Rang : 0 
    A = 
        1     2 
        3     4 
        5     6 
    B = 
        1     3     5     1     3 
        2     4     6     2     4 
    C = 
        5     11     17     5     11 
        11     25     39     11     25 
        17     33     61     17     39 

Section de références : 
    https://arel.eisti.fr/documents/67238 
    https://arel.eisti.fr/documents/67321 
    http://www.idris.fr/media/formations/mpi/idrismpitp.pdf 
    https://www.open-mpi.org/doc/v4.0/
